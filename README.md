# NumNet+v2 pretraining on GenBERT data

Pretraining NumNet+v2 on synthetic numeric and textual data, the way GenBERT was.

### Sources

Data and pretraining scheme: [github](https://github.com/ag1988/injecting_numeracy/tree/master/pre_training)

NumNet code was taken from: [github](https://github.com/llamazing/numnet_plus).
